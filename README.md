## Objective

To establish the usefulness of explainable AI (XAI) methods for Electroencephalogram (EEG) analysis. This case-study was done as part of the paper "Bridging AI and Health on Time Series Analysis and Explainability Using the Case Study of EEG Channel Selection Problem" for submission in AAAI25 workshop _Artificial Intelligence for Time Series Analysis (AI4TS): Theory, Algorithms, and Applications._

Contact: Vandana Srivastava, vandana@email.sc.edu, University of South Carolina
<br>
<br>

## Data and Methods

* LEMON EEG dataset (https://fcon_1000.projects.nitrc.org/indi/retro/MPI_LEMON.html)
* Mental Arithmetic EEG dataset from physionet (https://physionet.org/content/eegmat/1.0.0/)
* Explainable AI package: interpretML (https://github.com/interpretml/interpret?tab=readme-ov-file)

## Citation                
If you find this work useful, please cite:
```
@inproceedings{bridge-eeg-ai-aaai2025ws,
  title={Bridging AI and Health on Time Series Analysis and Explainability Using the Case Study of EEG Channel Selection Problem},
  author={Vandana Srivastava and Biplav Srivastava},
  booktitle={AAAI25 workshop Artificial Intelligence for Time Series Analysis (AI4TS): Theory, Algorithms, and Applications,
  year={2025}
}
```
